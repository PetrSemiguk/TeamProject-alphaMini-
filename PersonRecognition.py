import asyncio
import logging
import sys
import cv2
import time
from threading import Thread, Lock
import mini.mini_sdk as MiniSdk
from mini.dns.dns_browser import WiFiDevice
from mini.apis.base_api import MiniApiResultType
from mini.apis.api_sound import StartPlayTTS

# ================== CONFIGURATION ==================
MiniSdk.set_log_level(logging.INFO)
MiniSdk.set_robot_type(MiniSdk.RobotType.EDU)

ROBOT_ID = "412"
SEARCH_TIMEOUT = 20
CAMERA_ID = 6  # –ö–∞–º–µ—Ä–∞ –Ω–æ—É—Ç–±—É–∫–∞ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –¥–æ—Å—Ç—É–ø–Ω–∞—è)
MOTION_THRESHOLD = 3000  # –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏
REACTION_COOLDOWN = 8  # –°–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É —Ä–µ–∞–∫—Ü–∏—è–º–∏ —Ä–æ–±–æ—Ç–∞

# –§—Ä–∞–∑—ã –¥–ª—è —Ä–æ–±–æ—Ç–∞
REACTIONS = [
    "Welcome to PSB academy! I am your robot promoter. Nice to meet you!",
    "Hello there! Welcome to PSB academy. How can I help you today?",
    "Greetings! I'm here to tell you about PSB academy. Welcome!",
    "Hey! I noticed you. Can I tell you about our programs?"
]


# ================== MOTION DETECTOR (LAPTOP CAMERA) ==================
class MotionDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –¥–≤–∏–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –∫–∞–º–µ—Ä—É –Ω–æ—É—Ç–±—É–∫–∞"""

    def __init__(self, camera_id=0):
        self.camera_id = camera_id
        self.cap = None
        self.detection_active = False
        self.motion_detected = False
        self.last_detection_time = 0
        self.lock = Lock()
        self.prev_frame = None
        self.frame_count = 0

    def start(self):
        """–ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã –∏ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        try:
            print(f"[üì∑] Opening laptop camera (ID: {self.camera_id})...")
            self.cap = cv2.VideoCapture(self.camera_id)

            if not self.cap.isOpened():
                print("[‚ùå] Failed to open laptop camera!")
                print("[üí°] Make sure no other app is using the camera")
                return False

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞
            ret, test_frame = self.cap.read()
            if not ret:
                print("[‚ùå] Camera opened but cannot read frames!")
                return False

            print(f"[‚úì] Camera working! Resolution: {test_frame.shape[1]}x{test_frame.shape[0]}")

            self.detection_active = True

            # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
            detection_thread = Thread(target=self._detection_loop, daemon=True)
            detection_thread.start()

            print("[‚úì] Motion detection started!")
            return True

        except Exception as e:
            print(f"[‚ùå] Error starting camera: {e}")
            return False

    def _detection_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è"""
        print("\n" + "=" * 70)
        print("üëÅÔ∏è  MOTION DETECTION ACTIVE (USING LAPTOP CAMERA)")
        print("=" * 70)
        print("[‚ÑπÔ∏è]  Position laptop so camera sees the area in front of robot")
        print("[‚ÑπÔ∏è]  Move your hand or walk in front of camera to test")
        print("[‚ÑπÔ∏è]  Robot will speak when motion is detected")
        print("[‚ÑπÔ∏è]  Press Ctrl+C to stop")
        print("=" * 70 + "\n")

        while self.detection_active:
            try:
                ret, frame = self.cap.read()
                if not ret:
                    time.sleep(0.1)
                    continue

                self.frame_count += 1

                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ grayscale –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                gray = cv2.GaussianBlur(gray, (21, 21), 0)

                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ –∫–∞–¥—Ä–∞
                if self.prev_frame is None:
                    self.prev_frame = gray
                    continue

                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–Ω–∏—Ü—ã –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏
                frame_delta = cv2.absdiff(self.prev_frame, gray)
                thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]
                thresh = cv2.dilate(thresh, None, iterations=2)

                # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤ (–æ–±–ª–∞—Å—Ç–∏ –¥–≤–∏–∂–µ–Ω–∏—è)
                contours, _ = cv2.findContours(
                    thresh.copy(),
                    cv2.RETR_EXTERNAL,
                    cv2.CHAIN_APPROX_SIMPLE
                )

                # –ü–æ–¥—Å—á–µ—Ç –ø–ª–æ—â–∞–¥–∏ –¥–≤–∏–∂–µ–Ω–∏—è
                motion_area = 0
                for contour in contours:
                    area = cv2.contourArea(contour)
                    if area > 500:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –º–µ–ª–∫–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è (—à—É–º)
                        motion_area += area

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
                with self.lock:
                    current_time = time.time()

                    if motion_area > MOTION_THRESHOLD:
                        # –î–≤–∏–∂–µ–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!
                        if not self.motion_detected:
                            print(f"\nüî¥ MOTION DETECTED!")
                            print(f"   Area: {int(motion_area)} | Frame: #{self.frame_count}")

                        self.motion_detected = True
                        self.last_detection_time = current_time
                    else:
                        # –î–≤–∏–∂–µ–Ω–∏—è –Ω–µ—Ç
                        if current_time - self.last_detection_time > 1.5:
                            if self.motion_detected:
                                print("‚úÖ Motion stopped\n")
                            self.motion_detected = False

                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–∞–¥—Ä
                self.prev_frame = gray

                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                time.sleep(0.05)

            except Exception as e:
                print(f"[‚ùå] Detection error: {e}")
                time.sleep(0.5)

    def is_motion_detected(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–≤–∏–∂–µ–Ω–∏—è"""
        with self.lock:
            return self.motion_detected

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã"""
        print("\n[üîß] Stopping camera...")
        self.detection_active = False
        if self.cap:
            self.cap.release()
        print("[‚úì] Camera released")


# ================== ROBOT PROMOTER ==================
class RobotPromoter:
    """–†–æ–±–æ—Ç-–ø—Ä–æ–º–æ—É—Ç–µ—Ä —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –¥–≤–∏–∂–µ–Ω–∏—è"""

    def __init__(self):
        self.detector = MotionDetector(CAMERA_ID)
        self.last_reaction_time = 0
        self.reaction_index = 0
        self.is_reacting = False
        self.reaction_count = 0

    async def search_device_by_name(self, serial_number_suffix: str, timeout: int):
        """–ü–æ–∏—Å–∫ —Ä–æ–±–æ—Ç–∞ –≤ —Å–µ—Ç–∏"""
        try:
            print(f"[üîç] Searching for robot with ID: {serial_number_suffix}...")
            result = await MiniSdk.get_device_by_name(serial_number_suffix, timeout)
            print(f"[‚úì] Found robot: {result}")
            return result
        except Exception as e:
            print(f"[‚ùå] Error searching for device: {e}")
            return None

    async def connect_device(self, device):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Ä–æ–±–æ—Ç—É"""
        try:
            print(f"[üîå] Connecting to robot...")
            connected = await MiniSdk.connect(device)
            if connected:
                print(f"[‚úì] Successfully connected!")
                return True
            else:
                print("[‚ùå] Connection failed")
                return False
        except Exception as e:
            print(f"[‚ùå] Connection error: {e}")
            return False

    async def make_alphamini_speak(self, text: str):
        """–†–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç"""
        try:
            tts_block = StartPlayTTS(text=text)
            response = await tts_block.execute()

            if response.isSuccess:
                print(f"[üó£Ô∏è]  Robot: '{text}'")
                return True
            else:
                print(f"[‚ùå] Speech failed (code: {response.resultCode})")
                return False

        except Exception as e:
            print(f"[‚ùå] TTS error: {e}")
            return False

    async def react_to_motion(self):
        """–†–µ–∞–∫—Ü–∏—è –Ω–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ"""
        if self.is_reacting:
            return

        self.is_reacting = True
        current_time = time.time()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ cooldown
        if current_time - self.last_reaction_time < REACTION_COOLDOWN:
            self.is_reacting = False
            return

        self.reaction_count += 1

        print("\n" + "ü§ñ " * 25)
        print(f"‚ö° ROBOT REACTION #{self.reaction_count}")
        print("ü§ñ " * 25)

        # –í—ã–±–æ—Ä —Ñ—Ä–∞–∑—ã (—Ü–∏–∫–ª–∏—á–µ—Å–∫–∏)
        reaction = REACTIONS[self.reaction_index]
        self.reaction_index = (self.reaction_index + 1) % len(REACTIONS)

        # –†–æ–±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç
        success = await self.make_alphamini_speak(reaction)

        if success:
            self.last_reaction_time = current_time
            print(f"[‚úì] Reaction complete")
            print(f"[‚è≥] Next reaction available in {REACTION_COOLDOWN} seconds")
        else:
            print("[‚ö†Ô∏è]  Reaction failed, but continuing...")

        self.is_reacting = False
        print("ü§ñ " * 25 + "\n")

    async def detection_mode(self):
        """–†–µ–∂–∏–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏ —Ä–µ–∞–∫—Ü–∏–∏"""
        print("\n" + "=" * 70)
        print("üöÄ ROBOT PROMOTER - ACTIVE MODE")
        print("=" * 70)
        print("[‚ÑπÔ∏è]  Robot is now monitoring for movement")
        print("[‚ÑπÔ∏è]  When motion detected ‚Üí Robot will greet")
        print("[‚ÑπÔ∏è]  Position laptop camera to see visitor area")
        print("=" * 70 + "\n")

        while True:
            try:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–≤–∏–∂–µ–Ω–∏—è
                if self.detector.is_motion_detected():
                    await self.react_to_motion()

                await asyncio.sleep(0.3)

            except Exception as e:
                print(f"[‚ùå] Loop error: {e}")
                await asyncio.sleep(1)

    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π –∑–∞–ø—É—Å–∫"""
        print("\n" + "=" * 70)
        print("ü§ñ ALPHAMINI ROBOT PROMOTER - INITIALIZATION")
        print("=" * 70 + "\n")

        # –®–∞–≥ 1: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Ä–æ–±–æ—Ç—É
        print("[1/4] Connecting to robot...")
        device = await self.search_device_by_name(ROBOT_ID, SEARCH_TIMEOUT)
        if not device:
            print("[‚ùå] Robot not found!")
            print("[üí°] Check: 1) ROBOT_ID is correct, 2) Robot is on same network")
            return

        connected = await self.connect_device(device)
        if not connected:
            print("[‚ùå] Could not connect to robot!")
            return

        # –®–∞–≥ 2: –í—Ö–æ–¥ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π —Ä–µ–∂–∏–º
        print("\n[2/4] Entering programming mode...")
        await MiniSdk.enter_program()
        print("[‚úì] Programming mode active")
        await asyncio.sleep(1)

        # –®–∞–≥ 3: –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã
        print("\n[3/4] Starting laptop camera...")
        if not self.detector.start():
            print("[‚ùå] Camera initialization failed!")
            await MiniSdk.quit_program()
            await MiniSdk.release()
            return

        await asyncio.sleep(2)  # –ü—Ä–æ–≥—Ä–µ–≤ –∫–∞–º–µ—Ä—ã

        # –®–∞–≥ 4: –ó–∞–ø—É—Å–∫ —Ä–µ–∂–∏–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
        print("\n[4/4] Starting detection mode...")
        print("[‚úì] All systems ready!\n")

        try:
            await self.detection_mode()

        except KeyboardInterrupt:
            print("\n\n[üõë] Stopping robot promoter...")

        finally:
            # –û—á–∏—Å—Ç–∫–∞
            print("\n" + "=" * 70)
            print("üîß SHUTDOWN SEQUENCE")
            print("=" * 70)
            print(f"[üìä] Total reactions performed: {self.reaction_count}")

            self.detector.stop()

            await MiniSdk.quit_program()
            await MiniSdk.release()

            print("[‚úì] Robot disconnected")
            print("[‚úì] Camera released")
            print("[‚úì] Shutdown complete")
            print("=" * 70 + "\n")


# ================== MAIN ==================
async def main():
    promoter = RobotPromoter()
    await promoter.run()


if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("üé• ALPHAMINI ROBOT PROMOTER WITH LAPTOP CAMERA")
    print("=" * 70)
    print("System: AlphaMini EDU + Laptop Webcam")
    print("Method: Motion Detection ‚Üí Speech Response")
    print("=" * 70 + "\n")

    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n[!] Program interrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"\n[üí•] Critical error: {e}")
        sys.exit(1)